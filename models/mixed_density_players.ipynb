{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-31 16:02:12.573456: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-07-31 16:02:12.585471: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-31 16:02:12.594997: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-31 16:02:12.597689: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-31 16:02:12.604716: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-31 16:02:13.032879: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import keras_tuner as kt\n",
    "import tensorflow_probability as tfp\n",
    "import tensorflow as tf\n",
    "from sklearn.utils import class_weight\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "n_players_df = pd.read_csv(\"data/n_players_classifier.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "204"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = list(n_players_df.columns)\n",
    "columns = columns[columns.index(\"HomeTeamPlayer1_AST\"):columns.index(\"WL_A\")]\n",
    "len(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows where the target variable contains NaN\n",
    "df = n_players_df.dropna(subset=[\"WL_A\"])\n",
    "\n",
    "# Define features and target\n",
    "X = df[columns]\n",
    "y = df[\"WL_A\"]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# One-hot encode the target variable\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "# Apply SMOTE to balance the classes\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 30 Complete [00h 00m 21s]\n",
      "accuracy: 0.05025612562894821\n",
      "\n",
      "Best accuracy So Far: 0.604679524898529\n",
      "Total elapsed time: 00h 04m 18s\n"
     ]
    }
   ],
   "source": [
    "# Custom loss function for Mixture Density Network\n",
    "def mdn_loss(num_components):\n",
    "    def loss(y_true, y_pred):\n",
    "        y_true = tf.expand_dims(y_true, axis=-1)\n",
    "        gm = tfp.distributions.MixtureSameFamily(\n",
    "            mixture_distribution=tfp.distributions.Categorical(\n",
    "                logits=y_pred[:, :num_components]\n",
    "            ),\n",
    "            components_distribution=tfp.distributions.Normal(\n",
    "                loc=y_pred[:, num_components : num_components * 2],\n",
    "                scale=tf.nn.softplus(y_pred[:, num_components * 2 :]),\n",
    "            ),\n",
    "        )\n",
    "        return -gm.log_prob(y_true)\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "# Define the hypermodel with Mixture Density Network\n",
    "def build_model(hp):\n",
    "    model = Sequential()\n",
    "    model.add(\n",
    "        Dense(\n",
    "            units=hp.Int(\"units\", min_value=16, max_value=128, step=16),\n",
    "            activation=hp.Choice(\"activation\", values=[\"relu\", \"tanh\"]),\n",
    "            input_shape=(X_train.shape[1],),\n",
    "        )\n",
    "    )\n",
    "    model.add(Dropout(hp.Float(\"dropout\", min_value=0.0, max_value=0.5, step=0.1)))\n",
    "    model.add(\n",
    "        Dense(\n",
    "            units=hp.Int(\"units\", min_value=16, max_value=128, step=16),\n",
    "            activation=hp.Choice(\"activation\", values=[\"relu\", \"tanh\"]),\n",
    "        )\n",
    "    )\n",
    "    model.add(Dropout(hp.Float(\"dropout\", min_value=0.0, max_value=0.5, step=0.1)))\n",
    "\n",
    "    # Define the parameters for the mixture density network\n",
    "    num_components = hp.Int(\"num_components\", min_value=2, max_value=10, step=1)\n",
    "    model.add(\n",
    "        tf.keras.layers.Dense(num_components * 3)\n",
    "    )  # 3 parameters per component: mean, stddev, and weight\n",
    "\n",
    "    model.compile(optimizer=\"adam\", loss=mdn_loss(num_components), metrics=[\"accuracy\"])\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "tuner = kt.Hyperband(\n",
    "    build_model,\n",
    "    objective=kt.Objective(\"accuracy\", direction=\"max\"),\n",
    "    max_epochs=10,\n",
    "    factor=3,\n",
    "    directory=\"new_dir\",\n",
    "    project_name=\"nba_mdn_tuning\",\n",
    ")\n",
    "\n",
    "\n",
    "# Train the best model\n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor=\"val_accuracy\", patience=15)\n",
    "\n",
    "print(tuner)\n",
    "# Search for the best hyperparameters\n",
    "tuner.search(\n",
    "    X_train_resampled,\n",
    "    y_train_resampled,\n",
    "    epochs=50,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[stop_early],\n",
    ")\n",
    "\n",
    "# Get the best model\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "model = tuner.hypermodel.build(best_hps)\n",
    "\n",
    "# Compile the model with the custom loss\n",
    "num_components = best_hps.get(\"num_components\")\n",
    "model.compile(\n",
    "    optimizer=\"adam\", loss=mdn_loss(num_components), metrics=[\"accuracy\"]\n",
    ")  # Default optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'units': 32, 'activation': 'relu', 'dropout': 0.4, 'num_components': 9, 'tuner/epochs': 4, 'tuner/initial_epoch': 2, 'tuner/bracket': 2, 'tuner/round': 1, 'tuner/trial_id': '0010'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Get the best model\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "model = tuner.hypermodel.build(best_hps)\n",
    "\n",
    "# Compile the model with the custom loss\n",
    "num_components = best_hps.get(\"num_components\")\n",
    "model.compile(\n",
    "    optimizer=\"adam\", loss=mdn_loss(num_components), metrics=[\"accuracy\"]\n",
    ")  # Default optimizer\n",
    "\n",
    "print(best_hps.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0505 - loss: 0.9269 - val_accuracy: 0.0000e+00 - val_loss: -0.6560\n",
      "Epoch 2/20\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: -1.5160 - val_accuracy: 0.0000e+00 - val_loss: -2.6547\n",
      "Epoch 3/20\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: -3.0489 - val_accuracy: 0.0000e+00 - val_loss: 0.7919\n",
      "Epoch 4/20\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: -3.6936 - val_accuracy: 0.0000e+00 - val_loss: -4.2688\n",
      "Epoch 5/20\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: -4.0537 - val_accuracy: 0.0000e+00 - val_loss: -4.2076\n",
      "Epoch 6/20\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: -4.1149 - val_accuracy: 0.0000e+00 - val_loss: -1.8051\n",
      "Epoch 7/20\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: -3.2193 - val_accuracy: 0.0000e+00 - val_loss: -4.6407\n",
      "Epoch 8/20\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: -4.4121 - val_accuracy: 0.0000e+00 - val_loss: -3.7980\n",
      "Epoch 9/20\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: -4.8293 - val_accuracy: 0.0000e+00 - val_loss: -5.2291\n",
      "Epoch 10/20\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: -5.0517 - val_accuracy: 0.0000e+00 - val_loss: -5.1483\n",
      "Epoch 11/20\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: -4.7832 - val_accuracy: 0.0000e+00 - val_loss: -2.6730\n",
      "Epoch 12/20\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: -3.2807 - val_accuracy: 0.0000e+00 - val_loss: -4.6146\n",
      "Epoch 13/20\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: -4.7164 - val_accuracy: 0.0000e+00 - val_loss: -4.0351\n",
      "Epoch 14/20\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: -4.1854 - val_accuracy: 0.0000e+00 - val_loss: -5.4215\n",
      "Epoch 15/20\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: -4.6838 - val_accuracy: 0.0000e+00 - val_loss: -5.4205\n",
      "Epoch 16/20\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: -4.5157 - val_accuracy: 0.0000e+00 - val_loss: -0.8804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-31 16:07:03.200958: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: INVALID_ARGUMENT: Incompatible shapes: [32] vs. [32,2]\n",
      "\t [[{{node Equal}}]]\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node Equal defined at (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n\n  File \"/home/rohanbendapudi/MLenv/lib/python3.10/site-packages/ipykernel_launcher.py\", line 18, in <module>\n\n  File \"/home/rohanbendapudi/MLenv/lib/python3.10/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n\n  File \"/home/rohanbendapudi/MLenv/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 739, in start\n\n  File \"/home/rohanbendapudi/MLenv/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 205, in start\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n\n  File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n\n  File \"/home/rohanbendapudi/MLenv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n\n  File \"/home/rohanbendapudi/MLenv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n\n  File \"/home/rohanbendapudi/MLenv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n\n  File \"/home/rohanbendapudi/MLenv/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n\n  File \"/home/rohanbendapudi/MLenv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n\n  File \"/home/rohanbendapudi/MLenv/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n\n  File \"/home/rohanbendapudi/MLenv/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n\n  File \"/home/rohanbendapudi/MLenv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3075, in run_cell\n\n  File \"/home/rohanbendapudi/MLenv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3130, in _run_cell\n\n  File \"/home/rohanbendapudi/MLenv/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n\n  File \"/home/rohanbendapudi/MLenv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3334, in run_cell_async\n\n  File \"/home/rohanbendapudi/MLenv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3517, in run_ast_nodes\n\n  File \"/home/rohanbendapudi/MLenv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n\n  File \"/tmp/ipykernel_409449/811798200.py\", line 6, in <module>\n\n  File \"/home/rohanbendapudi/MLenv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/home/rohanbendapudi/MLenv/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py\", line 429, in evaluate\n\n  File \"/home/rohanbendapudi/MLenv/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py\", line 165, in one_step_on_iterator\n\n  File \"/home/rohanbendapudi/MLenv/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py\", line 154, in one_step_on_data\n\n  File \"/home/rohanbendapudi/MLenv/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py\", line 91, in test_step\n\n  File \"/home/rohanbendapudi/MLenv/lib/python3.10/site-packages/keras/src/trainers/trainer.py\", line 444, in compute_metrics\n\n  File \"/home/rohanbendapudi/MLenv/lib/python3.10/site-packages/keras/src/trainers/compile_utils.py\", line 330, in update_state\n\n  File \"/home/rohanbendapudi/MLenv/lib/python3.10/site-packages/keras/src/trainers/compile_utils.py\", line 17, in update_state\n\n  File \"/home/rohanbendapudi/MLenv/lib/python3.10/site-packages/keras/src/metrics/reduction_metrics.py\", line 204, in update_state\n\n  File \"/home/rohanbendapudi/MLenv/lib/python3.10/site-packages/keras/src/metrics/accuracy_metrics.py\", line 246, in sparse_categorical_accuracy\n\n  File \"/home/rohanbendapudi/MLenv/lib/python3.10/site-packages/keras/src/ops/numpy.py\", line 2355, in equal\n\n  File \"/home/rohanbendapudi/MLenv/lib/python3.10/site-packages/keras/src/backend/tensorflow/numpy.py\", line 1144, in equal\n\nIncompatible shapes: [32] vs. [32,2]\n\t [[{{node Equal}}]] [Op:__inference_one_step_on_iterator_510194]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m history \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(\n\u001b[1;32m      2\u001b[0m     X_train_resampled, y_train_resampled, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m, validation_split\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, callbacks\u001b[38;5;241m=\u001b[39m[stop_early]\n\u001b[1;32m      3\u001b[0m )\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Evaluate the model on the test set\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest Mixture Density Network loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Make predictions\u001b[39;00m\n",
      "File \u001b[0;32m~/MLenv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/MLenv/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node Equal defined at (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n\n  File \"/home/rohanbendapudi/MLenv/lib/python3.10/site-packages/ipykernel_launcher.py\", line 18, in <module>\n\n  File \"/home/rohanbendapudi/MLenv/lib/python3.10/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n\n  File \"/home/rohanbendapudi/MLenv/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 739, in start\n\n  File \"/home/rohanbendapudi/MLenv/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 205, in start\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n\n  File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n\n  File \"/home/rohanbendapudi/MLenv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n\n  File \"/home/rohanbendapudi/MLenv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n\n  File \"/home/rohanbendapudi/MLenv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n\n  File \"/home/rohanbendapudi/MLenv/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n\n  File \"/home/rohanbendapudi/MLenv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n\n  File \"/home/rohanbendapudi/MLenv/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n\n  File \"/home/rohanbendapudi/MLenv/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n\n  File \"/home/rohanbendapudi/MLenv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3075, in run_cell\n\n  File \"/home/rohanbendapudi/MLenv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3130, in _run_cell\n\n  File \"/home/rohanbendapudi/MLenv/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n\n  File \"/home/rohanbendapudi/MLenv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3334, in run_cell_async\n\n  File \"/home/rohanbendapudi/MLenv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3517, in run_ast_nodes\n\n  File \"/home/rohanbendapudi/MLenv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n\n  File \"/tmp/ipykernel_409449/811798200.py\", line 6, in <module>\n\n  File \"/home/rohanbendapudi/MLenv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/home/rohanbendapudi/MLenv/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py\", line 429, in evaluate\n\n  File \"/home/rohanbendapudi/MLenv/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py\", line 165, in one_step_on_iterator\n\n  File \"/home/rohanbendapudi/MLenv/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py\", line 154, in one_step_on_data\n\n  File \"/home/rohanbendapudi/MLenv/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py\", line 91, in test_step\n\n  File \"/home/rohanbendapudi/MLenv/lib/python3.10/site-packages/keras/src/trainers/trainer.py\", line 444, in compute_metrics\n\n  File \"/home/rohanbendapudi/MLenv/lib/python3.10/site-packages/keras/src/trainers/compile_utils.py\", line 330, in update_state\n\n  File \"/home/rohanbendapudi/MLenv/lib/python3.10/site-packages/keras/src/trainers/compile_utils.py\", line 17, in update_state\n\n  File \"/home/rohanbendapudi/MLenv/lib/python3.10/site-packages/keras/src/metrics/reduction_metrics.py\", line 204, in update_state\n\n  File \"/home/rohanbendapudi/MLenv/lib/python3.10/site-packages/keras/src/metrics/accuracy_metrics.py\", line 246, in sparse_categorical_accuracy\n\n  File \"/home/rohanbendapudi/MLenv/lib/python3.10/site-packages/keras/src/ops/numpy.py\", line 2355, in equal\n\n  File \"/home/rohanbendapudi/MLenv/lib/python3.10/site-packages/keras/src/backend/tensorflow/numpy.py\", line 1144, in equal\n\nIncompatible shapes: [32] vs. [32,2]\n\t [[{{node Equal}}]] [Op:__inference_one_step_on_iterator_510194]"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train_resampled, y_train_resampled, epochs=5, validation_split=0.2, verbose=1, callbacks=[stop_early]\n",
    ")\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "loss = model.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "print(f\"Best Mixture Density Network loss: {loss}\")\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "# Convert predictions to categorical outputs for evaluation\n",
    "gm = tfp.distributions.MixtureSameFamily(\n",
    "    mixture_distribution=tfp.distributions.Categorical(\n",
    "        logits=y_pred[:, :num_components]\n",
    "    ),\n",
    "    components_distribution=tfp.distributions.Normal(\n",
    "        loc=y_pred[:, num_components : num_components * 2],\n",
    "        scale=tf.nn.softplus(y_pred[:, num_components * 2 :]),\n",
    "    ),\n",
    ")\n",
    "y_pred_proba = gm.mean().numpy()  # Convert Tensor to NumPy array\n",
    "\n",
    "# Ensure exactly half wins and half losses\n",
    "num_samples = len(y_pred_proba)\n",
    "num_wins = num_samples // 2\n",
    "num_losses = num_samples - num_wins\n",
    "\n",
    "# Get indices for the top probabilities for wins\n",
    "indices_sorted = np.argsort(y_pred_proba.flatten())\n",
    "indices_wins = indices_sorted[-num_wins:]\n",
    "indices_losses = indices_sorted[:-num_wins]\n",
    "\n",
    "# Create the final predictions\n",
    "y_pred_final = np.zeros(num_samples)\n",
    "y_pred_final[indices_wins] = 1  # Mark top probabilities as wins\n",
    "# Remaining are losses\n",
    "\n",
    "# Convert y_test from one-hot encoded format to single integer labels\n",
    "y_test_single = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Best Mixture Density Network classification report:\")\n",
    "print(classification_report(y_test_single, y_pred_final))\n",
    "\n",
    "# Confusion matrix\n",
    "conf_matrix_mdn = confusion_matrix(y_test_single, y_pred_final)\n",
    "sns.heatmap(conf_matrix_mdn, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
