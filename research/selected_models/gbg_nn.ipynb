{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras_tuner'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 20\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BatchNormalization\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dropout\n\u001b[0;32m---> 20\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mkeras_tuner\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mkt\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dropout\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m keras\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'keras_tuner'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.preprocessing as skp\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.decomposition import PCA\n",
    "import sklearn.ensemble\n",
    "import sklearn.linear_model\n",
    "from sklearn import neighbors\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import sklearn.metrics as metrics\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Dropout\n",
    "import keras_tuner as kt\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow import keras\n",
    "\n",
    "import os\n",
    "# change os directory up one level\n",
    "os.chdir(os.path.dirname(os.getcwd()))\n",
    "from api_helpers.game_stats_helpers import load_past_n_games\n",
    "# change os directory back \n",
    "os.chdir(os.path.join(os.getcwd(), 'selected_models'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    all_games_df = pd.read_csv(\"../data/all_games.csv\",encoding=\"utf-8\")\n",
    "    all_games_df.drop(\"Unnamed: 0\", axis=1,inplace=True)\n",
    "    all_games_df = all_games_df.dropna()\n",
    "    all_games_df = all_games_df[all_games_df['WL_A'] != ' ']\n",
    "    X = all_games_df.drop(columns=[\"WL_A\", \"WL_B\"])\n",
    "    y = all_games_df[\"WL_A\"]\n",
    "    le = skp.LabelEncoder()\n",
    "    y = le.fit_transform(y)\n",
    "    return all_games_df, X, y\n",
    "\n",
    "def data_prep(all_games_df, columns=[\"FG_PCT\",\"FT_PCT\", \"OREB\", \"TOV\", \"DREB\", \"AST\"]):\n",
    "    columns_a = [column + \"_A\" for column in columns]\n",
    "    columns_b = [column + \"_B\" for column in columns]\n",
    "\n",
    "    n_games_df = load_past_n_games(all_games_df=all_games_df, columns=columns, n=20)\n",
    "    n_games_df = n_games_df.dropna()\n",
    "\n",
    "    x_columns = columns_a + columns_b\n",
    "    y_column = \"WL_A\"\n",
    "\n",
    "    #normalize x_data\n",
    "    scaler = skp.StandardScaler()\n",
    "    n_games_df[x_columns] = scaler.fit_transform(n_games_df[x_columns])\n",
    "    # save scaler\n",
    "    # joblib.dump(scaler, 'last20_scaler.bin')\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(n_games_df[x_columns], n_games_df[y_column], test_size=0.2, random_state=42)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       SEASON_ID   TEAM_ID_A TEAM_ABBREVIATION_A        TEAM_NAME_A   GAME_ID  \\\n",
      "0          22023  1610612737                 ATL      Atlanta Hawks  22301159   \n",
      "1          22023  1610612737                 ATL      Atlanta Hawks  22301147   \n",
      "2          22023  1610612737                 ATL      Atlanta Hawks  22301104   \n",
      "3          22023  1610612737                 ATL      Atlanta Hawks  22301076   \n",
      "4          22023  1610612737                 ATL      Atlanta Hawks  22301060   \n",
      "...          ...         ...                 ...                ...       ...   \n",
      "52468      21996  1610612766                 CHH  Charlotte Hornets  29600141   \n",
      "52469      21996  1610612766                 CHH  Charlotte Hornets  29600107   \n",
      "52470      21996  1610612766                 CHH  Charlotte Hornets  29600064   \n",
      "52471      21996  1610612766                 CHH  Charlotte Hornets  29600044   \n",
      "52472      21996  1610612766                 CHH  Charlotte Hornets  29600016   \n",
      "\n",
      "        GAME_DATE    MATCHUP_A WL_A  MIN_A  PTS_A  ...  FT_PCT_B  OREB_B  \\\n",
      "0      2024-04-10  ATL vs. CHA    L    240    114  ...     0.955     5.0   \n",
      "1      2024-04-09  ATL vs. MIA    L    292    111  ...     0.714     5.0   \n",
      "2      2024-04-03  ATL vs. DET    W    240    121  ...     0.810     8.0   \n",
      "3      2024-03-30  ATL vs. MIL    L    239    113  ...     0.800     6.0   \n",
      "4      2024-03-28  ATL vs. BOS    W    265    123  ...     0.857     9.0   \n",
      "...           ...          ...  ...    ...    ...  ...       ...     ...   \n",
      "52468  1996-11-20  CHH vs. NYK    W    240     93  ...     0.778     8.0   \n",
      "52469  1996-11-15  CHH vs. CHI    L    240     87  ...     0.786    14.0   \n",
      "52470  1996-11-09  CHH vs. MIL    L    240     98  ...     0.727    10.0   \n",
      "52471  1996-11-06  CHH vs. LAL    W    239     88  ...     0.727     9.0   \n",
      "52472  1996-11-02  CHH vs. TOR    W    241    109  ...     0.667    10.0   \n",
      "\n",
      "       DREB_B  REB_B  AST_B  STL_B  BLK_B  TOV_B  PF_B  PLUS_MINUS_B  \n",
      "0        28.0   33.0     25   11.0      2     13    18           1.0  \n",
      "1        41.0   46.0     29    8.0      3     18    16           6.0  \n",
      "2        29.0   37.0     24   14.0      3     10    13          -8.0  \n",
      "3        34.0   40.0     27    7.0      5     10    18           9.0  \n",
      "4        34.0   43.0     28    7.0      6     12    15          -1.0  \n",
      "...       ...    ...    ...    ...    ...    ...   ...           ...  \n",
      "52468    29.0   37.0     14    4.0      5     20    31          -7.0  \n",
      "52469    31.0   45.0     29    9.0      3     20    16          23.0  \n",
      "52470    27.0   37.0     17    5.0      3     11    27           2.0  \n",
      "52471    31.0   40.0     22    1.0      7     16    19         -10.0  \n",
      "52472    24.0   34.0     17    5.0      5     11    29         -11.0  \n",
      "\n",
      "[37945 rows x 53 columns]\n"
     ]
    }
   ],
   "source": [
    "all_games_df, X,y = get_data()\n",
    "print(all_games_df)\n",
    "X_train, X_test, y_train, y_test = data_prep(all_games_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'kt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 31\u001b[0m\n\u001b[1;32m     20\u001b[0m     model\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[1;32m     21\u001b[0m         optimizer\u001b[38;5;241m=\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39mhp_learning_rate),\n\u001b[1;32m     22\u001b[0m         loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     23\u001b[0m         metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     24\u001b[0m     )\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n\u001b[0;32m---> 31\u001b[0m tuner \u001b[38;5;241m=\u001b[39m \u001b[43mkt\u001b[49m\u001b[38;5;241m.\u001b[39mHyperband(\n\u001b[1;32m     32\u001b[0m     model_builder,\n\u001b[1;32m     33\u001b[0m     objective\u001b[38;5;241m=\u001b[39mkt\u001b[38;5;241m.\u001b[39mObjective(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_accuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m, direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m     34\u001b[0m     max_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,\n\u001b[1;32m     35\u001b[0m     factor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,\n\u001b[1;32m     36\u001b[0m     directory\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmy_dir\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     37\u001b[0m     project_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthird\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     38\u001b[0m )\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28mprint\u001b[39m(tuner)\n\u001b[1;32m     42\u001b[0m stop_early \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mEarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'kt' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def model_builder(hp):\n",
    "    model = Sequential()\n",
    "\n",
    "    hp_units = hp.Int(\"units\", min_value=16, max_value=128, step=32)\n",
    "\n",
    "    hp_learning_rate = hp.Choice(\"learning_rate\", values=[1e-2, 1e-3, 1e-4])\n",
    "\n",
    "    activations = hp.Choice(\"activation\", values=[\"relu\", \"tanh\"])\n",
    "    final_activation = hp.Choice(\"activation\", values=[\"sigmoid\", \"softmax\"])\n",
    "\n",
    "    model.add(keras.Input(shape=(14,)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(hp.Float(\"dropout\", min_value=0.0, max_value=0.5, step=0.1)))\n",
    "    model.add(Dense(units=hp_units, activation=activations))\n",
    "    model.add(Dropout(hp.Float(\"dropout\", min_value=0.0, max_value=0.5, step=0.1)))\n",
    "    model.add(Dense(units=hp_units, activation=activations))\n",
    "    model.add(Dropout(hp.Float(\"dropout\", min_value=0.0, max_value=0.5, step=0.1)))\n",
    "    model.add(Dense(2, activation=\"sigmoid\"))\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "tuner = kt.Hyperband(\n",
    "    model_builder,\n",
    "    objective=kt.Objective(\"val_accuracy\", direction=\"max\"),\n",
    "    max_epochs=10,\n",
    "    factor=3,\n",
    "    directory=\"my_dir\",\n",
    "    project_name=\"third\",\n",
    ")\n",
    "\n",
    "print(tuner)\n",
    "\n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=5)\n",
    "\n",
    "tuner.search(X_train, y_train, epochs=5,\n",
    "             validation_split=0.2, callbacks=[stop_early])\n",
    "\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "model = tuner.hypermodel.build(best_hps)\n",
    "\n",
    "print(best_hps)\n",
    "\n",
    "print(\n",
    "    f\"\"\"\n",
    "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
    "layer is {best_hps.get('units')} and the optimal learning rate for the optimizer\n",
    "is {best_hps.get('learning_rate')}.\n",
    "\"\"\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
